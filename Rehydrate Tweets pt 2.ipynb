{
 "metadata": {
  "name": "Rehydrate Tweets pt 2",
  "signature": "sha256:161a3cd59cc7fff081803cb15cb6c2835ad429cd43e8245006b9d0816307ef4a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Import python modules to connect to twitter, import CSV files, and connect to mongodb"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import tweepy\nimport csv\n%pylab inline\nfrom pymongo import MongoClient\n# Connect to mongodb\nclient = MongoClient()",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Store your Twitter API Keys"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Store your consumer keys and access tokens\nconsumer_key = ''\nconsumer_secret = ''\n\naccess_token = ''\naccess_secret= ''",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Authentication with Twitter"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\nauth.set_access_token(access_token, access_secret)\n\napi = tweepy.API(auth)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Open file containing list of tweets"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "tf = open('/var/data/sanders-twitter-0.2/corpus.csv')",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Read the file as a CSV using the CSV reader"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "tweets = csv.reader(tf)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Create an output file in your home directgory -- notice the 'w' is used for write mode"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "otf = open('/home/stw3/full-corpus.csv', 'w')",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Create a CSV writer for easier access to the file\nwriter = csv.writer( otf, delimiter=',', quotechar='\"', escapechar='\\\\', quoting=csv.QUOTE_ALL )\n# write header row\nwriter.writerow( ['Topic','Sentiment','TweetId','TweetDate','TweetText'] )",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Your turn! Loop through the file retrieving each tweet using the tweet id as we go. Store the correct fields in the output CSV file.\n\nKeep track of the tweets that are no longer avaialble as you go."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Look through each line of the CSV file (no in tweets)\nfor line in tweets:\n    # We need to use a try/except block because deleted tweets/accounts return an\n    # exception which, if uncaught, will kill our program.\n    try:\n        # Use the Twitter REST API to retrieve the tweet\n        # The third field in the data file contains the tweet id\n        tweet = api.get_status(line[2])\n        \n        # Now write all to out data file use the CSV Writer\n        # the writer takes an array of items\n        # The columns are topic, sentiment, tweet id, tweet date (from API), text (from API)\n        writer.writerow([line[0], line[1], line[2], tweet.created_at, tweet.text])\n\n    # Catch the exception thrown when we encounter a delted tweet\n    # The exception thrown is a TweetError.\n    except tweepy.TweepError, e:\n        print(\"Tweet delted \", e, line[2])",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Close the output file to flush the cache\notf.close()\n\n# Since we are going to work with the data file again\n# Seek back up to the top of the file\ntf.seek(0)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "##It's your turn again\n\nNow modify the steps above to save the tweets directly to mongodb -- don't forget to save the 'Topic' and 'Sentiment' into the tweet!\n\n**Hint: We alraedy connected to mongo when we imported our libraries at the begining of the file**"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "##Descriptive Stats\nUsing mongo queries, retrive or calculate the following informaiton from the data you just inserted:\n- Number of tweets\n- Number of unique screen names\n- Screen name with highest followers\n- Screen name with the least followers\n- Number of tweets per topic\n- Number of tweets with each sentiment (positive, negative, irrelevant, neutral) per topic (create a histogram of this also)\n- How many retweets"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}